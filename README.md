# PySpark-Project-Build-a-Data-Pipeline-using-Hive-and-Cassandra

- Understanding the project overview
- Create an AWS EC2 instance and launch it.
- Create docker images using docker-compose file on EC2 machine via ssh.
- Dockerization
- Introduction to PySpark
- Introduction to Apache Hive
- Introduction to Apache Cassandra
- Need for PySpark integration
- Understanding the concept of ETL
- Difference between ETL and ELT
- PySpark integration with Apache Hive
- PySpark integration with Apache Cassandra
